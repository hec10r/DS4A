{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon\n",
    "import shapely.wkt\n",
    "from itertools import permutations\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working directory is C:\\Users\\Hector\\Documents\\DS4A_datathon\n",
      "The datasets folder is  C:\\Users\\Hector\\Documents\\DS4A_datathon\\Datasets\n"
     ]
    }
   ],
   "source": [
    "## Define the working directory. (This should be executed just once)\n",
    "os.chdir(os.path.join('..'))\n",
    "working_path = os.getcwd()\n",
    "\n",
    "print('The working directory is {}'.format(working_path))\n",
    "\n",
    "# Define the path where the data sets are located\n",
    "datasets_path = os.path.join(working_path, 'Datasets')\n",
    "\n",
    "print('The datasets folder is  {}'.format(datasets_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define paths for each dataset\n",
    "boroughs_path = os.path.join(datasets_path, 'boroughs.json')\n",
    "uber_trips_2014 = os.path.join(datasets_path, 'uber_trips_2014.csv')\n",
    "uber_trips_2015 = os.path.join(datasets_path, 'uber_trips_2015.csv')\n",
    "zones = os.path.join(datasets_path, 'zones.csv')\n",
    "\n",
    "\n",
    "## Create dataframe for each dataset\n",
    "\n",
    "df_uber_trips_2014 = pd.read_csv(uber_trips_2014)\n",
    "df_uber_trips_2015 = pd.read_csv(uber_trips_2015)\n",
    "df_zones = pd.read_csv(zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open json file to get Borough's Polygons\n",
    "with open(boroughs_path) as json_file:\n",
    "    boroughs_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create objects to store significant data\n",
    "boroughs_polygon = dict()\n",
    "boroughs_name = list()\n",
    "\n",
    "# Fill objects\n",
    "boroughs = boroughs_data['data']\n",
    "for borough in boroughs:\n",
    "    boroughs_polygon[borough[10]] = shapely.wkt.loads(borough[9])\n",
    "    boroughs_name.append(borough[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to check if two polygons have intersection\n",
    "def exists_intersection(p1, p2):\n",
    "    '''\n",
    "    Check wether or not polygons have an intersection area\n",
    "    '''\n",
    "    return p1.intersection(p2).area != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the polygons don't intersect each other\n",
    "for name in permutations(boroughs_name, 2):\n",
    "    if exists_intersection(boroughs_polygon[name[0]], boroughs_polygon[name[1]]):\n",
    "        print('The boroughs {} and {} are not disjunt'.format(name[0], name[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_polygon(df, polygon_dict, latitud_col='lat', longitude_col='lon', \n",
    "                   error_msg='Does not belong to any', final_col_name='polygon',\n",
    "                   sample_size=None):\n",
    "    \n",
    "    def which_polygon(row):\n",
    "        \n",
    "        lat = row[latitud_col]\n",
    "        long = row[longitude_col]\n",
    "        \n",
    "        for id_, pol in polygon_dict.items():\n",
    "            if pol.contains(Point(long, lat)):\n",
    "                return id_\n",
    "        return error_msg\n",
    "    \n",
    "    \n",
    "    if sample_size is None:\n",
    "        df2 = df.copy()\n",
    "    else:\n",
    "        df2 = df[:sample_size].copy()\n",
    "    \n",
    "    df2[final_col_name] = df2.apply(lambda row: which_polygon(row), axis=1)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_datetime', 'pickup_latitude', 'pickup_longitude', 'base'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uber_trips_2014.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_datetime', 'pickup_location_id', 'dispatch_base',\n",
       "       'affiliate_base'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uber_trips_2015.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns that will be in the final dataset\n",
    "final_columns = ['pickup_datetime', 'affiliate_base', 'borough']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesado_2014 = append_polygon(df_uber_trips_2014, boroughs_polygon,\n",
    "                              latitud_col='pickup_latitude',\n",
    "                              longitude_col='pickup_longitude',\n",
    "                              error_msg='Does not belong to any borough',\n",
    "                              final_col_name='borough', sample_size=None).rename(columns={'base': 'affiliate_base'})\n",
    "\n",
    "\n",
    "df_procesado_2014['pickup_datetime'] = pd.to_datetime(df_procesado_2014['pickup_datetime'])\n",
    "df_procesado_2014 = df_procesado_2014[final_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hector\\.conda\\envs\\DS4A_test\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.merge(\n",
    "            df_uber_trips_2015, \n",
    "            df_zones, \n",
    "            how='left', \n",
    "            left_on='pickup_location_id', \n",
    "            right_on='location_id')\n",
    "\n",
    "df_procesado_2015 = df_raw[['pickup_datetime', 'dispatch_base', 'affiliate_base', 'zone', 'borough', 'service_zone', 'nta_code']]\n",
    "df_procesado_2015['pickup_datetime'] = pd.to_datetime(df_procesado_2015['pickup_datetime'])\n",
    "df_procesado_2015 = df_procesado_2015[final_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_proccess_file = os.path.join(datasets_path, 'uber_processed.csv')\n",
    "\n",
    "df_uber = pd.concat([df_procesado_2014, df_procesado_2015], ignore_index=True)\n",
    "df_uber.to_csv(path_proccess_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>affiliate_base</th>\n",
       "      <th>borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2014-04-01 00:11:00</td>\n",
       "      <td>B02512</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-01 00:17:00</td>\n",
       "      <td>B02512</td>\n",
       "      <td>Does not belong to any borough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2014-04-01 00:21:00</td>\n",
       "      <td>B02512</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2014-04-01 00:28:00</td>\n",
       "      <td>B02512</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2014-04-01 00:33:00</td>\n",
       "      <td>B02512</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pickup_datetime affiliate_base                         borough\n",
       "0 2014-04-01 00:11:00         B02512                       Manhattan\n",
       "1 2014-04-01 00:17:00         B02512  Does not belong to any borough\n",
       "2 2014-04-01 00:21:00         B02512                       Manhattan\n",
       "3 2014-04-01 00:28:00         B02512                       Manhattan\n",
       "4 2014-04-01 00:33:00         B02512                       Manhattan"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uber.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
